[0m[[0m[31merror[0m] [0m[0morg.apache.spark.SparkException: Invalid Spark URL: spark://HeartbeatReceiver@User -2024PLTAS:59529[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rpc.RpcEndpointAddress$.apply(RpcEndpointAddress.scala:71)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:140)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.executor.Executor.<init>(Executor.scala:250)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.local.LocalEndpoint.<init>(LocalSchedulerBackend.scala:64)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.local.LocalSchedulerBackend.start(LocalSchedulerBackend.scala:132)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:235)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.SparkContext.<init>(SparkContext.scala:590)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2740)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1026)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.Option.getOrElse(Option.scala:189)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1020)[0m
[0m[[0m[31merror[0m] [0m[0m	at MongoDBKafka$.main(MongodbKafka.scala:32)[0m
[0m[[0m[31merror[0m] [0m[0m	at MongoDBKafka.main(MongodbKafka.scala)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.lang.reflect.Method.invoke(Method.java:566)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.invokeMain(Run.scala:135)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.execute$1(Run.scala:85)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:112)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run$.executeSuccess(Run.scala:178)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.runWithLoader(Run.scala:112)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:2072)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:2011)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.util.Try$.apply(Try.scala:213)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:378)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.lang.Thread.run(Thread.java:829)[0m
[0m[[0m[31merror[0m] [0m[0mCaused by: java.net.URISyntaxException: Illegal character in authority at index 8: spark://HeartbeatReceiver@User -2024PLTAS:59529[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.net.URI$Parser.fail(URI.java:2913)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.net.URI$Parser.parseAuthority(URI.java:3261)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.net.URI$Parser.parseHierarchical(URI.java:3158)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.net.URI$Parser.parse(URI.java:3114)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.net.URI.<init>(URI.java:600)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rpc.RpcEndpointAddress$.apply(RpcEndpointAddress.scala:55)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:140)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.executor.Executor.<init>(Executor.scala:250)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.local.LocalEndpoint.<init>(LocalSchedulerBackend.scala:64)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.local.LocalSchedulerBackend.start(LocalSchedulerBackend.scala:132)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:235)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.SparkContext.<init>(SparkContext.scala:590)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2740)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1026)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.Option.getOrElse(Option.scala:189)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1020)[0m
[0m[[0m[31merror[0m] [0m[0m	at MongoDBKafka$.main(MongodbKafka.scala:32)[0m
[0m[[0m[31merror[0m] [0m[0m	at MongoDBKafka.main(MongodbKafka.scala)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.lang.reflect.Method.invoke(Method.java:566)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.invokeMain(Run.scala:135)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.execute$1(Run.scala:85)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:112)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run$.executeSuccess(Run.scala:178)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.runWithLoader(Run.scala:112)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:2072)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:2011)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.util.Try$.apply(Try.scala:213)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:378)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.lang.Thread.run(Thread.java:829)[0m
[0m[[0m[31merror[0m] [0m[0m(Compile / [31mrun[0m) org.apache.spark.SparkException: Invalid Spark URL: spark://HeartbeatReceiver@User -2024PLTAS:59529[0m
