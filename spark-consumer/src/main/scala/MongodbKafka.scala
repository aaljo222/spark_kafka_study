import org.apache.spark.sql.{SparkSession, functions => F}
import org.apache.spark.sql.types._
import sttp.client3.quick._
import sttp.client3.UriContext
import sttp.client3.HttpClientSyncBackend

object MongoDBKafka {

  // Slack ì•Œë¦¼ í•¨ìˆ˜ (ì§ë ¬í™” ëŒ€ìƒ ì•„ë‹˜)
  def sendSlackAlert(sensorId: String, temp: Double, webhook: String): Unit = {
    if (temp > 35.0 && webhook.nonEmpty) {
      val backend = HttpClientSyncBackend()
      val msg = s"""{"text": "ðŸš¨ Alert! $sensorId temperature is $tempÂ°C"}"""
      quickRequest
        .post(uri"$webhook")
        .body(msg)
        .contentType("application/json")
        .send(backend)
      backend.close()
    }
  }

  def main(args: Array[String]): Unit = {
    val kafkaBroker = sys.env.getOrElse("KAFKA_BROKER", "localhost:9092")
    val topicName = sys.env.getOrElse("TOPIC_NAME", "sensor-health")
    val mongoUri = sys.env.getOrElse("MONGO_URI", "mongodb://localhost:27017/sensorDB.readings")
    val slackWebhook = sys.env.getOrElse("SLACK_WEBHOOK", "")

    val spark = SparkSession.builder()
      .appName("KafkaToMongoDB")
      .master("local[*]")
      .config("spark.mongodb.write.connection.uri", mongoUri)
      .getOrCreate()

    import spark.implicits._

    val schema = StructType(Seq(
      StructField("sensor_id", StringType),
      StructField("temperature", DoubleType),
      StructField("timestamp", LongType)
    ))

    val kafkaDF = spark.readStream
      .format("kafka")
      .option("kafka.bootstrap.servers", kafkaBroker)
      .option("subscribePattern", "sensor-health|event-topic")
      .option("startingOffsets", "latest")
      .load()

    val parsed = kafkaDF.selectExpr("CAST(value AS STRING) as json")
      .select(F.from_json(F.col("json"), schema).as("data"))
      .select("data.*")

    // âŒ Slack ì•Œë¦¼ì€ ì—¬ê¸°ì„œ í•˜ì§€ ì•ŠìŒ. ëŒ€ì‹  ë‚˜ì¤‘ì— í›„ì²˜ë¦¬
    val withAlertFlag = parsed.withColumn(
      "alert_flag",
      F.when(F.col("temperature") > 35.0, F.lit(true)).otherwise(F.lit(false))
    )

    val query = withAlertFlag.writeStream
      .format("mongodb")
      .option("checkpointLocation", "/tmp/kafka-to-mongo-checkpoint")
      .outputMode("append")
      .start()

    println("âœ… Streaming started. Slack alerts should be triggered externally based on MongoDB data.")
    query.awaitTermination()
  }
}
