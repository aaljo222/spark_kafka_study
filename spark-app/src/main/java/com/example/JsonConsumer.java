package com.example;

import io.github.cdimascio.dotenv.Dotenv;
import org.apache.kafka.clients.consumer.*;

import java.time.Duration;
import java.util.Collections;
import java.util.Properties;

public class JsonConsumer {
    public static void main(String[] args) {
        Dotenv dotenv = Dotenv.configure()
                .directory("spark-app") // ë˜ëŠ” ì ˆëŒ€ê²½ë¡œ
                .load();

        System.out.println("ğŸ“¦ .env í™˜ê²½ë³€ìˆ˜ ë””ë²„ê¹… -------------------");
        // ì£¼ìš” ë³€ìˆ˜ ì¶œë ¥
        System.out.println("âœ… KAFKA_BROKER:   " + dotenv.get("KAFKA_BROKER"));
        System.out.println("âœ… MONGO_URI:      " + dotenv.get("MONGO_URI"));
        System.out.println("âœ… SLACK_WEBHOOK:  " + dotenv.get("SLACK_WEBHOOK"));


        System.out.println("--------------------------------------------");
        String kafkaBroker = dotenv.get("KAFKA_BROKER", "kafka:9092");

        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBroker);  // â† ì ìš©

        props.put(ConsumerConfig.GROUP_ID_CONFIG, "json-group");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer");
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer");

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList("sensor-stream"));
        System.out.println("ğŸŸ¢ Kafka Consumer êµ¬ë™ ì¤‘...");

        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
            for (ConsumerRecord<String, String> record : records) {
                System.out.println("ğŸ“¥ JSON ë©”ì‹œì§€ ìˆ˜ì‹ : " + record.value());
            }
        }
    }
}
